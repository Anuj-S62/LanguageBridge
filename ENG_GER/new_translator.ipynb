{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 50\n",
    "UNITS = 50\n",
    "NUM_EPOCHS = 20\n",
    "max_lines = 180000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent, exclude, sp_tokens=False):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(\"'\", '', sent)\n",
    "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(\" +\", \" \", sent)\n",
    "    if sp_tokens:\n",
    "        sent = '<start> ' + sent + ' <end>'\n",
    "    \n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def Tokenize(text):\n",
    "    tokenizer = Tokenizer(oov_token=\"<unk>\",filters='!\"#$%&()*+,-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def pad_sequences(x, max_len):\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=max_len, padding='post', truncating='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!', 'Run!\\tLauf!', 'Wow!\\tPotzdonner!', 'Wow!\\tDonnerwetter!']\n"
     ]
    }
   ],
   "source": [
    "lines = load_data(\"eng_ger.txt\")\n",
    "lines = lines[:max_lines]\n",
    "\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(lines):\n",
    "    data = []\n",
    "    exclude = string.punctuation\n",
    "    for line in lines:\n",
    "        text = line.split(\"\\t\")\n",
    "        prep_inp = preprocess(text[0], exclude=exclude, sp_tokens=False)\n",
    "        prep_tar = preprocess(text[1], exclude=exclude, sp_tokens=True)\n",
    "        data.append([prep_inp, prep_tar])\n",
    "    \n",
    "    print(data[:5])\n",
    "    \n",
    "    # tokenize\n",
    "    inp_tokenizer = Tokenize([i[0] for i in data])\n",
    "    tar_tokenizer = Tokenize([i[1] for i in data])\n",
    "\n",
    "    # convert text to sequences\n",
    "    inp_seq = inp_tokenizer.texts_to_sequences([i[0] for i in data])\n",
    "    tar_seq = tar_tokenizer.texts_to_sequences([i[1] for i in data])\n",
    "\n",
    "    print(inp_seq[:5])\n",
    "    print(tar_seq[:5])\n",
    "\n",
    "    # padding\n",
    "    inp_seq = pad_sequences(inp_seq, max_len=10)\n",
    "    tar_seq = pad_sequences(tar_seq, max_len=10)\n",
    "\n",
    "    print(inp_seq[:5])\n",
    "    print(tar_seq[:5])\n",
    "\n",
    "    input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(inp_seq, tar_seq, test_size=0.2)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(len(input_tensor_val))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "    return train_dataset, test_dataset, inp_tokenizer, tar_tokenizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', '<start> hallo <end>'], ['hi', '<start> grüß gott <end>'], ['run', '<start> lauf <end>'], ['wow', '<start> potzdonner <end>'], ['wow', '<start> donnerwetter <end>']]\n",
      "[[2057], [2057], [459], [3724], [3724]]\n",
      "[[2, 1598, 3], [2, 4079, 1515, 3], [2, 4510, 3], [2, 10096, 3], [2, 12454, 3]]\n",
      "[[2057    0    0    0    0    0    0    0    0    0]\n",
      " [2057    0    0    0    0    0    0    0    0    0]\n",
      " [ 459    0    0    0    0    0    0    0    0    0]\n",
      " [3724    0    0    0    0    0    0    0    0    0]\n",
      " [3724    0    0    0    0    0    0    0    0    0]]\n",
      "[[    2  1598     3     0     0     0     0     0     0     0]\n",
      " [    2  4079  1515     3     0     0     0     0     0     0]\n",
      " [    2  4510     3     0     0     0     0     0     0     0]\n",
      " [    2 10096     3     0     0     0     0     0     0     0]\n",
      " [    2 12454     3     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, inp_tokenizer, tar_tokenizer = combine(lines)\n",
    "input_vocab_size = len(inp_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(tar_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 10), dtype=tf.int32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(token,tokenizer):\n",
    "    # token = token.numpy()\n",
    "    res = \"\"\n",
    "    for i in token:\n",
    "        if i!=0:\n",
    "            if(tokenizer.index_word[i]==\"<end>\"):\n",
    "                break\n",
    "            if(tokenizer.index_word[i]==\"<start>\"):\n",
    "                continue\n",
    "            res += tokenizer.index_word[i] + \" \"\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layers => 1 embedding layer and 1 LSTM layer\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, units, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim, mask_zero=True)\n",
    "        self.rnn = tf.keras.layers.LSTM(\n",
    "            units, return_sequences=True, return_state=True)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # x => (batch_size, max_len)\n",
    "        x = self.embedding(x) # => (batch_size, s, embed_dim)\n",
    "        enc_outputs = self.rnn(x)\n",
    "        return enc_outputs[0], enc_outputs[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W_q = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W_k = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W_v = tf.keras.layers.Dense(1, use_bias=False)\n",
    "    \n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        query, key = self.W_q(query), self.W_k(key)\n",
    "        # query => (batch_size, t, units)\n",
    "        # key => (batch_size, s, units)\n",
    "\n",
    "        score = self.W_v(\n",
    "            tf.math.tanh(\n",
    "                tf.expand_dims(query, 2) + tf.expand_dims(key, 1)\n",
    "            )\n",
    "        )\n",
    "        score = tf.squeeze(score, -1)\n",
    "        # score => (batch_size, t, s)\n",
    "        \n",
    "        if mask is not None:\n",
    "            score = tf.where(mask, score, -1e6)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        # attention_weights => (batch_size, t, s)\n",
    "\n",
    "        context = tf.matmul(attention_weights, value)\n",
    "        # context => (batch_size, t, units)\n",
    "\n",
    "        return context, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, units, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer to convert tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim, mask_zero=True)\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = tf.keras.layers.LSTM(\n",
    "            units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = AdditiveAttention(units)\n",
    "\n",
    "        # Final layer to output logits, we can use \n",
    "        # argmax to know which output token is predicted.\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "\n",
    "    def call(self, x, enc_outputs, state, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        # x => (batch_size, t, embed_dim)\n",
    "\n",
    "        dec_outputs = self.rnn(x, initial_state=state)\n",
    "        output = dec_outputs[0]\n",
    "        state = dec_outputs[1:]\n",
    "        # output   => (batch_size, t, units) \n",
    "        # state[i] => (batch_size, s, units)\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            query=output,\n",
    "            key=enc_outputs,\n",
    "            value=enc_outputs,\n",
    "            mask=mask\n",
    "        )\n",
    "        # context_vector => (batch_size, t, units)\n",
    "        # attention_weights => (batch_size, t, s)\n",
    "\n",
    "        context_rnn_output = tf.concat(\n",
    "            [context_vector, output], axis=-1)\n",
    "        # context_rnn_output => (batch_size, t, 2*units)\n",
    "\n",
    "        pred = self.fc(context_rnn_output)\n",
    "        # pred => (batch_size, t, vocab_size)\n",
    "        \n",
    "        return pred, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instances of encoder and decoder\n",
    "encoder = Encoder(EMBEDDING_DIM, UNITS, input_vocab_size)\n",
    "decoder = Decoder(EMBEDDING_DIM, UNITS, target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    # y_true => (batch_size, max_len)\n",
    "    # y_pred => (batch_size, max_len, vocab_size)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # masking the padding tokens\n",
    "    loss = tf.reduce_sum(loss * mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "trainer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'loss': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [10:15<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 3.0401213541030883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:56<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.788059564696418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:57<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 1.4489450137880113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:59<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 1.2759853318267398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:52<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 1.1762304315037198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:50<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 1.1178003440697988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:49<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 1.0739805550045438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:49<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 1.045177271074719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:51<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 1.0219092377291785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:52<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 1.0025466074148814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:52<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.9876225637065039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:56<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 0.9767847358915541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:54<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 0.9678186881012387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:50<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 0.9580294948418935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:52<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 0.9528588523334927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:54<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 0.9462892627186246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [10:01<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 0.9444270656903585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [09:57<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 0.9391775285402933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [10:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 0.934206871509552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [10:00<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 0.9309811730914646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0.\n",
    "\n",
    "    with tqdm(total=len(train_dataset)) as pbar:\n",
    "        for batch, (x, y) in enumerate(train_dataset):\n",
    "            inp_mask = tf.expand_dims(x != 0, axis=1)\n",
    "            tgt_mask = tf.cast(y != 0, tf.float32)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = tf.constant(0.0)\n",
    "                enc_outputs, enc_states = encoder(x)\n",
    "                dec_states = enc_states\n",
    "\n",
    "                dec_input = tf.expand_dims(y[:, 0], axis=1)\n",
    "                for t in range(1, x.shape[1]):\n",
    "                    dec_outputs, dec_states, tmp_a = decoder(\n",
    "                        dec_input, enc_outputs, \n",
    "                        dec_states, inp_mask)\n",
    "\n",
    "                    loss += loss_fn(\n",
    "                        tf.expand_dims(y[:, t], axis=1), dec_outputs)\n",
    "                    dec_input = tf.expand_dims(y[:, t], axis=1)\n",
    "                    \n",
    "                loss = loss/tf.reduce_sum(tgt_mask)\n",
    "            \n",
    "            variables = (encoder.trainable_variables + \n",
    "            decoder.trainable_variables)\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            trainer.apply_gradients(zip(gradients, variables))\n",
    "            total_loss += loss.numpy()\n",
    "            pbar.update(1)\n",
    "        \n",
    "    epoch_loss = total_loss/len(train_dataset)\n",
    "    history['loss'].append(epoch_loss)\n",
    "    print(f'Epoch: {epoch} | Loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = list(range(len(history['loss'])))\n",
    "plt.plot(epochs, history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_tokenizer.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(encoder, decoder, src_tokens, tar_tokenizer, num_steps):\n",
    "    enc_X = tf.expand_dims(src_tokens, axis=0)\n",
    "    mask = tf.expand_dims(enc_X != 0, 1)\n",
    "\n",
    "    enc_outputs, enc_state = encoder(enc_X, training=False)\n",
    "    dec_state = enc_state\n",
    "    dec_X = tf.expand_dims(tf.constant([tar_tokenizer.word_index['<start>']]), axis=0)\n",
    "    output_seq = []\n",
    "    attention_weights = []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state, att_wgts = decoder(\n",
    "            dec_X, enc_outputs, dec_state, mask,training=False)\n",
    "        dec_X = tf.argmax(Y, axis=2)\n",
    "        pred = tf.squeeze(dec_X, axis=0)\n",
    "        if pred[0].numpy() == tar_tokenizer.word_index['<end>']:\n",
    "            break\n",
    "        output_seq.append(pred[0].numpy())\n",
    "        attention_weights.append(tf.squeeze(att_wgts, 0))\n",
    "    attention_weights = tf.squeeze(tf.stack(attention_weights, axis=0), 1)\n",
    "    return detokenize(output_seq, tar_tokenizer), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng, hin = next(iter(train_dataset))\n",
    "# print(train_dataset)\n",
    "# print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom participated in the boston marathon \n",
      "English Sentence:      tom participated in the boston marathon \n",
      "Predicted Translation: city city gehörst gehörst hats beginne harvardpullover harvardpullover dollar hotelreservation \n",
      "Actual Translation:    tom nahm am bostonmarathon teil \n"
     ]
    }
   ],
   "source": [
    "idx = -5\n",
    "actual_seq = detokenize(hin[idx].numpy(),tar_tokenizer)\n",
    "translation, att_wgts = predict_seq2seq(encoder, decoder, eng[idx], tar_tokenizer, 10)\n",
    "eng_sent = detokenize(eng[idx].numpy(), inp_tokenizer)\n",
    "print(eng_sent)\n",
    "print(f'English Sentence:      {eng_sent}')\n",
    "print(f'Predicted Translation: {translation}')\n",
    "print(f'Actual Translation:    {actual_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(lines,inp_tokenizer,tar_tokenizer,encoder,decoder,max_len=10):\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    prep_lines = []\n",
    "\n",
    "    for i in lines:\n",
    "        prep_lines.append([preprocess(i, exclude, sp_tokens=False)])\n",
    "    \n",
    "    input_tensors = []\n",
    "\n",
    "    for i in prep_lines:\n",
    "        inp = i[0].split(' ')\n",
    "        tensor = []\n",
    "        for j in inp:\n",
    "            # check for oov\n",
    "            if j not in inp_tokenizer.word_index.keys():\n",
    "                tensor.append(inp_tokenizer.word_index['<unk>'])\n",
    "            else:\n",
    "                tensor.append(inp_tokenizer.word_index[j])\n",
    "        input_tensors.append(tensor)\n",
    "            \n",
    "    for input_tensor in input_tensors:\n",
    "        temp_max_len = max(max_len,len(input_tensor))\n",
    "        for i in range(temp_max_len-len(input_tensor)):\n",
    "            input_tensor.append(0)\n",
    "\n",
    "    for input_tensor in input_tensors:\n",
    "        input_tensor = tf.convert_to_tensor(input_tensor)\n",
    "\n",
    "    translations = []\n",
    "\n",
    "    for input_tensor in input_tensors:\n",
    "        translation, _ = predict_seq2seq(encoder, decoder, input_tensor, tar_tokenizer,10)\n",
    "        translations.append(translation)\n",
    "    \n",
    "    print(translations) \n",
    "    \n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algaddafi weltfriedens nachholen mörder“ sonderbehandlung windhose windhose windhose braucht hinterhalt ', 'lastwagenfahrer blöd zeigten lastwagenfahrer blöd zeigten janeiro exakte änderung oberste ']\n",
      "['algaddafi weltfriedens nachholen mörder“ sonderbehandlung windhose windhose windhose braucht hinterhalt ', 'lastwagenfahrer blöd zeigten lastwagenfahrer blöd zeigten janeiro exakte änderung oberste ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"anuj\",\"how are you?\"],inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(lines,encoder = encoder,decoder = decoder,inp_tokenizer = inp_tokenizer,tar_tokenizer = tar_tokenizer):\n",
    "    translation = {'Tokenised Original':[],'Reference':[],'Translation':[]}\n",
    "    lines = lines[:50]\n",
    "    text = []\n",
    "    ref = []\n",
    "    trans = []\n",
    "    for i in lines:\n",
    "        t = i.split('\\t')\n",
    "        text.append(t[0])\n",
    "        ref.append(t[1])   \n",
    "    trans = translate(text,inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder)\n",
    "    for i in range(len(trans)):\n",
    "        translation['Tokenised Original'].append(text[i])\n",
    "        translation['Reference'].append(ref[i])\n",
    "        translation['Translation'].append(trans[i])\n",
    "    df = pd.DataFrame(translation)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vierbuchstabigen verdächtigen standardeinstellungen 1952 standardeinstellungen 1952 mitglied pflanzte psychopath „gleich ', 'vierbuchstabigen verdächtigen standardeinstellungen 1952 standardeinstellungen 1952 mitglied pflanzte psychopath „gleich ', 'schiff whitman whitman itsutsugistraße rasierte „möchtest überhäufte behandle militärgeschichte export ', 'vierbuchstabigen überraschenderweise eingebrockt deutsche belasten staatsbürger blättern misstraust polizeizelle raubüberfalls ', 'vierbuchstabigen überraschenderweise eingebrockt deutsche belasten staatsbürger blättern misstraust polizeizelle raubüberfalls ', 'hast jungenname nachrichtenbeitrag nachrichtenbeitrag vertrauen vertrauen 1689 beerdigt ermitteln zusammengebracht ', 'überflogen vertreibst „mehr klimaanlange vergleichbares gebellt gebellt wasserglass lehre exmann ', 'überflogen vertreibst „mehr klimaanlange vergleichbares gebellt gebellt wasserglass lehre exmann ', 'nacharbeiten lächerlicher vertreibst anstelle organische untergrundbahnstation untergrundbahnstation robotern dolch robotern ', 'unübersehbar beseitigt beseitigt bewerben anlangte currygericht siebzig einstellen erschrick leuchteten ', 'flüchtling gerichte verfasste unverschämtes paris statistik terminplans saite nr bewohnern ', 'vergütung dessen kampfkunst geraume zeitloses verlorene lektion zuteilt flamencoaufführungen seien ', 'bulle verendeten bulle untergrundbahn doofen geschuldet gesetzen geschuldet zusammenfassen division ', 'eingestürzt familienleben sag’s photogen falschliege spektakulär spektakulär straßenkampf glänzt glänzt ', 'eingestürzt familienleben sag’s photogen falschliege spektakulär spektakulär straßenkampf glänzt glänzt ', 'necke anonymen alleinstehende runterzuspülen glänzt glänzt wirkst vorheizen zurückzuerhalten zurückzuerhalten ', 'haustier fangt vonseiten knirscht hintertür dir“ veranlassten kuscheltiersammlung vergraben veranlassten ', 'haustier fangt vonseiten knirscht hintertür dir“ veranlassten kuscheltiersammlung vergraben veranlassten ', 'lebensbedrohlich schwangeren hockte blechdach schwangeren hockte ausreichend blechdach verbrannten krach ', 'lernten kanadische geldbeutels begreift unleidlich dunklen fußballspiele vorspielte vorspielte hall“ ', 'grinst libelle klassischen riesenpandas aufleuchten wortgewandt verdrossenen verdrossenen verdrossenen verdrossenen ', 'grinst libelle klassischen riesenpandas aufleuchten wortgewandt verdrossenen verdrossenen verdrossenen verdrossenen ', 'zwingt schenkte kompetent kompetent verzehrter verzehrter blümchenkleid blümchenkleid blümchenkleid blümchenkleid ', 'zwingt schenkte kompetent kompetent verzehrter verzehrter blümchenkleid blümchenkleid blümchenkleid blümchenkleid ', 'zwingt schenkte kompetent kompetent verzehrter verzehrter blümchenkleid blümchenkleid blümchenkleid blümchenkleid ', 'jubelten allemal aufgibst sekretär brandes geschäftsreise jackentasche brandes buchdruck posierte ', 'jubelten allemal aufgibst sekretär brandes geschäftsreise jackentasche brandes buchdruck posierte ', 'berichte berichte billiges passfoto ausbreiten überstundenmachen kilometer schuster lebensversicherungsvertrag biobauernhof ', '6 fachmediziner missgönnen wehtut achilles prinzip hättet unternehmensleitung erleichtern sags ', '6 fachmediziner missgönnen wehtut achilles prinzip hättet unternehmensleitung erleichtern sags ', '6 fachmediziner missgönnen wehtut achilles prinzip hättet unternehmensleitung erleichtern sags ', 'durchdringende durchdringende dichten eulen eulen gelebt überraschten bedeuteten sag’s sag’s ', 'durchdringende durchdringende dichten eulen eulen gelebt überraschten bedeuteten sag’s sag’s ', 'durchdringende durchdringende dichten eulen eulen gelebt überraschten bedeuteten sag’s sag’s ', 'durchdringende durchdringende dichten eulen eulen gelebt überraschten bedeuteten sag’s sag’s ', 'durchdringende durchdringende dichten eulen eulen gelebt überraschten bedeuteten sag’s sag’s ', 'kunstwerke kunstwerke erziehung glücken schrift stockdunkle erziehung schrift erwähne generationen ', 'freizuhaben ziegen“ freizuhaben ziegen“ rechtens ökonomie rechtens freizuhaben schlagloch griff ', 'libelle nervenkitzel verendeten verendeten verdrossenen verdrossenen verdrossenen verdrossenen verdrossenen verdrossenen ', 'kunstwerke kunstwerke „darauf erziehung erziehung schreib bestrebung bestrebung stockdunkle ziele ', 'kunstwerke kunstwerke „darauf erziehung erziehung schreib bestrebung bestrebung stockdunkle ziele ', 'fangt rauszukommen frottieren herausforderung abgemacht lakritze hausfrauen technologieunternehmen rar verliert ', 'entfernte spektakulär nötigen langweiler gelddiebstahl abhaben computerkurs goldstandard dasselbe 5 ', 'beriet verängstigt umgehst addressierte knabe kokainsüchtig romeo doppelte atome doppelte ', 'beriet verängstigt umgehst addressierte knabe kokainsüchtig romeo doppelte atome doppelte ', 'weiher gehaltskürzung atmosphäre bewerben geburts schubs schubs amerikanischem ire bemitleidenswert ', 'weiher gehaltskürzung atmosphäre bewerben geburts schubs schubs amerikanischem ire bemitleidenswert ', 'weiher atmosphäre erwischt ertrinkenden tapferes ertrinkenden berief vorstandes vorstandes zusätzlich ', 'weiher atmosphäre erwischt ertrinkenden tapferes ertrinkenden berief vorstandes vorstandes zusätzlich ', 'einlenken gedauert dümmer überschwemmung wiederfand stattete machts vierbuchstabigen lumpur stattete ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenised Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hallo!</td>\n",
       "      <td>vierbuchstabigen verdächtigen standardeinstell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Grüß Gott!</td>\n",
       "      <td>vierbuchstabigen verdächtigen standardeinstell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lauf!</td>\n",
       "      <td>schiff whitman whitman itsutsugistraße rasiert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Potzdonner!</td>\n",
       "      <td>vierbuchstabigen überraschenderweise eingebroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Donnerwetter!</td>\n",
       "      <td>vierbuchstabigen überraschenderweise eingebroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Feuer!</td>\n",
       "      <td>hast jungenname nachrichtenbeitrag nachrichten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Hilfe!</td>\n",
       "      <td>überflogen vertreibst „mehr klimaanlange vergl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Zu Hülf!</td>\n",
       "      <td>überflogen vertreibst „mehr klimaanlange vergl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>Stopp!</td>\n",
       "      <td>nacharbeiten lächerlicher vertreibst anstelle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>Warte!</td>\n",
       "      <td>unübersehbar beseitigt beseitigt bewerben anla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Go on.</td>\n",
       "      <td>Mach weiter.</td>\n",
       "      <td>flüchtling gerichte verfasste unverschämtes pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>Hallo!</td>\n",
       "      <td>vergütung dessen kampfkunst geraume zeitloses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I ran.</td>\n",
       "      <td>Ich rannte.</td>\n",
       "      <td>bulle verendeten bulle untergrundbahn doofen g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Ich verstehe.</td>\n",
       "      <td>eingestürzt familienleben sag’s photogen falsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Aha.</td>\n",
       "      <td>eingestürzt familienleben sag’s photogen falsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I try.</td>\n",
       "      <td>Ich probiere es.</td>\n",
       "      <td>necke anonymen alleinstehende runterzuspülen g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I won!</td>\n",
       "      <td>Ich hab gewonnen!</td>\n",
       "      <td>haustier fangt vonseiten knirscht hintertür di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I won!</td>\n",
       "      <td>Ich habe gewonnen!</td>\n",
       "      <td>haustier fangt vonseiten knirscht hintertür di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Smile.</td>\n",
       "      <td>Lächeln!</td>\n",
       "      <td>lebensbedrohlich schwangeren hockte blechdach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cheers!</td>\n",
       "      <td>Zum Wohl!</td>\n",
       "      <td>lernten kanadische geldbeutels begreift unleid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Freeze!</td>\n",
       "      <td>Keine Bewegung!</td>\n",
       "      <td>grinst libelle klassischen riesenpandas aufleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Freeze!</td>\n",
       "      <td>Stehenbleiben!</td>\n",
       "      <td>grinst libelle klassischen riesenpandas aufleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Kapiert?</td>\n",
       "      <td>zwingt schenkte kompetent kompetent verzehrter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Verstanden?</td>\n",
       "      <td>zwingt schenkte kompetent kompetent verzehrter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Einverstanden?</td>\n",
       "      <td>zwingt schenkte kompetent kompetent verzehrter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>He ran.</td>\n",
       "      <td>Er rannte.</td>\n",
       "      <td>jubelten allemal aufgibst sekretär brandes ges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>He ran.</td>\n",
       "      <td>Er lief.</td>\n",
       "      <td>jubelten allemal aufgibst sekretär brandes ges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hop in.</td>\n",
       "      <td>Mach mit!</td>\n",
       "      <td>berichte berichte billiges passfoto ausbreiten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Drück mich!</td>\n",
       "      <td>6 fachmediziner missgönnen wehtut achilles pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Nimm mich in den Arm!</td>\n",
       "      <td>6 fachmediziner missgönnen wehtut achilles pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Umarme mich!</td>\n",
       "      <td>6 fachmediziner missgönnen wehtut achilles pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich fiel.</td>\n",
       "      <td>durchdringende durchdringende dichten eulen eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich fiel hin.</td>\n",
       "      <td>durchdringende durchdringende dichten eulen eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich stürzte.</td>\n",
       "      <td>durchdringende durchdringende dichten eulen eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich bin hingefallen.</td>\n",
       "      <td>durchdringende durchdringende dichten eulen eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich bin gestürzt.</td>\n",
       "      <td>durchdringende durchdringende dichten eulen eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I know.</td>\n",
       "      <td>Ich weiß.</td>\n",
       "      <td>kunstwerke kunstwerke erziehung glücken schrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I lied.</td>\n",
       "      <td>Ich habe gelogen.</td>\n",
       "      <td>freizuhaben ziegen“ freizuhaben ziegen“ rechte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I lost.</td>\n",
       "      <td>Ich habe verloren.</td>\n",
       "      <td>libelle nervenkitzel verendeten verendeten ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I paid.</td>\n",
       "      <td>Ich habe bezahlt.</td>\n",
       "      <td>kunstwerke kunstwerke „darauf erziehung erzieh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I paid.</td>\n",
       "      <td>Ich zahlte.</td>\n",
       "      <td>kunstwerke kunstwerke „darauf erziehung erzieh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I sang.</td>\n",
       "      <td>Ich sang.</td>\n",
       "      <td>fangt rauszukommen frottieren herausforderung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I swim.</td>\n",
       "      <td>Ich schwimme.</td>\n",
       "      <td>entfernte spektakulär nötigen langweiler geldd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>Ich bin 19 Jahre alt.</td>\n",
       "      <td>beriet verängstigt umgehst addressierte knabe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>Ich bin 19.</td>\n",
       "      <td>beriet verängstigt umgehst addressierte knabe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>Mir geht's gut.</td>\n",
       "      <td>weiher gehaltskürzung atmosphäre bewerben gebu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>Es geht mir gut.</td>\n",
       "      <td>weiher gehaltskürzung atmosphäre bewerben gebu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I'm up.</td>\n",
       "      <td>Ich bin wach.</td>\n",
       "      <td>weiher atmosphäre erwischt ertrinkenden tapfer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I'm up.</td>\n",
       "      <td>Ich bin auf.</td>\n",
       "      <td>weiher atmosphäre erwischt ertrinkenden tapfer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>No way!</td>\n",
       "      <td>Unmöglich!</td>\n",
       "      <td>einlenken gedauert dümmer überschwemmung wiede...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tokenised Original              Reference  \\\n",
       "0                 Hi.                 Hallo!   \n",
       "1                 Hi.             Grüß Gott!   \n",
       "2                Run!                  Lauf!   \n",
       "3                Wow!            Potzdonner!   \n",
       "4                Wow!          Donnerwetter!   \n",
       "5               Fire!                 Feuer!   \n",
       "6               Help!                 Hilfe!   \n",
       "7               Help!               Zu Hülf!   \n",
       "8               Stop!                 Stopp!   \n",
       "9               Wait!                 Warte!   \n",
       "10             Go on.           Mach weiter.   \n",
       "11             Hello!                 Hallo!   \n",
       "12             I ran.            Ich rannte.   \n",
       "13             I see.          Ich verstehe.   \n",
       "14             I see.                   Aha.   \n",
       "15             I try.       Ich probiere es.   \n",
       "16             I won!      Ich hab gewonnen!   \n",
       "17             I won!     Ich habe gewonnen!   \n",
       "18             Smile.               Lächeln!   \n",
       "19            Cheers!              Zum Wohl!   \n",
       "20            Freeze!        Keine Bewegung!   \n",
       "21            Freeze!         Stehenbleiben!   \n",
       "22            Got it?               Kapiert?   \n",
       "23            Got it?            Verstanden?   \n",
       "24            Got it?         Einverstanden?   \n",
       "25            He ran.             Er rannte.   \n",
       "26            He ran.               Er lief.   \n",
       "27            Hop in.              Mach mit!   \n",
       "28            Hug me.            Drück mich!   \n",
       "29            Hug me.  Nimm mich in den Arm!   \n",
       "30            Hug me.           Umarme mich!   \n",
       "31            I fell.              Ich fiel.   \n",
       "32            I fell.          Ich fiel hin.   \n",
       "33            I fell.           Ich stürzte.   \n",
       "34            I fell.   Ich bin hingefallen.   \n",
       "35            I fell.      Ich bin gestürzt.   \n",
       "36            I know.              Ich weiß.   \n",
       "37            I lied.      Ich habe gelogen.   \n",
       "38            I lost.     Ich habe verloren.   \n",
       "39            I paid.      Ich habe bezahlt.   \n",
       "40            I paid.            Ich zahlte.   \n",
       "41            I sang.              Ich sang.   \n",
       "42            I swim.          Ich schwimme.   \n",
       "43            I'm 19.  Ich bin 19 Jahre alt.   \n",
       "44            I'm 19.            Ich bin 19.   \n",
       "45            I'm OK.        Mir geht's gut.   \n",
       "46            I'm OK.       Es geht mir gut.   \n",
       "47            I'm up.          Ich bin wach.   \n",
       "48            I'm up.           Ich bin auf.   \n",
       "49            No way!             Unmöglich!   \n",
       "\n",
       "                                          Translation  \n",
       "0   vierbuchstabigen verdächtigen standardeinstell...  \n",
       "1   vierbuchstabigen verdächtigen standardeinstell...  \n",
       "2   schiff whitman whitman itsutsugistraße rasiert...  \n",
       "3   vierbuchstabigen überraschenderweise eingebroc...  \n",
       "4   vierbuchstabigen überraschenderweise eingebroc...  \n",
       "5   hast jungenname nachrichtenbeitrag nachrichten...  \n",
       "6   überflogen vertreibst „mehr klimaanlange vergl...  \n",
       "7   überflogen vertreibst „mehr klimaanlange vergl...  \n",
       "8   nacharbeiten lächerlicher vertreibst anstelle ...  \n",
       "9   unübersehbar beseitigt beseitigt bewerben anla...  \n",
       "10  flüchtling gerichte verfasste unverschämtes pa...  \n",
       "11  vergütung dessen kampfkunst geraume zeitloses ...  \n",
       "12  bulle verendeten bulle untergrundbahn doofen g...  \n",
       "13  eingestürzt familienleben sag’s photogen falsc...  \n",
       "14  eingestürzt familienleben sag’s photogen falsc...  \n",
       "15  necke anonymen alleinstehende runterzuspülen g...  \n",
       "16  haustier fangt vonseiten knirscht hintertür di...  \n",
       "17  haustier fangt vonseiten knirscht hintertür di...  \n",
       "18  lebensbedrohlich schwangeren hockte blechdach ...  \n",
       "19  lernten kanadische geldbeutels begreift unleid...  \n",
       "20  grinst libelle klassischen riesenpandas aufleu...  \n",
       "21  grinst libelle klassischen riesenpandas aufleu...  \n",
       "22  zwingt schenkte kompetent kompetent verzehrter...  \n",
       "23  zwingt schenkte kompetent kompetent verzehrter...  \n",
       "24  zwingt schenkte kompetent kompetent verzehrter...  \n",
       "25  jubelten allemal aufgibst sekretär brandes ges...  \n",
       "26  jubelten allemal aufgibst sekretär brandes ges...  \n",
       "27  berichte berichte billiges passfoto ausbreiten...  \n",
       "28  6 fachmediziner missgönnen wehtut achilles pri...  \n",
       "29  6 fachmediziner missgönnen wehtut achilles pri...  \n",
       "30  6 fachmediziner missgönnen wehtut achilles pri...  \n",
       "31  durchdringende durchdringende dichten eulen eu...  \n",
       "32  durchdringende durchdringende dichten eulen eu...  \n",
       "33  durchdringende durchdringende dichten eulen eu...  \n",
       "34  durchdringende durchdringende dichten eulen eu...  \n",
       "35  durchdringende durchdringende dichten eulen eu...  \n",
       "36  kunstwerke kunstwerke erziehung glücken schrif...  \n",
       "37  freizuhaben ziegen“ freizuhaben ziegen“ rechte...  \n",
       "38  libelle nervenkitzel verendeten verendeten ver...  \n",
       "39  kunstwerke kunstwerke „darauf erziehung erzieh...  \n",
       "40  kunstwerke kunstwerke „darauf erziehung erzieh...  \n",
       "41  fangt rauszukommen frottieren herausforderung ...  \n",
       "42  entfernte spektakulär nötigen langweiler geldd...  \n",
       "43  beriet verängstigt umgehst addressierte knabe ...  \n",
       "44  beriet verängstigt umgehst addressierte knabe ...  \n",
       "45  weiher gehaltskürzung atmosphäre bewerben gebu...  \n",
       "46  weiher gehaltskürzung atmosphäre bewerben gebu...  \n",
       "47  weiher atmosphäre erwischt ertrinkenden tapfer...  \n",
       "48  weiher atmosphäre erwischt ertrinkenden tapfer...  \n",
       "49  einlenken gedauert dümmer überschwemmung wiede...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df(lines)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('encoder_attention_v1.pickle', 'wb') as f:\n",
    "#     pickle.dump(encoder, f)\n",
    "# with open('decoder_attention_v1.pickle', 'wb') as f:\n",
    "#     pickle.dump(decoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algaddafi weltfriedens nachholen mörder“ sonderbehandlung windhose windhose windhose braucht hinterhalt ', 'lastwagenfahrer blöd zeigten lastwagenfahrer blöd zeigten janeiro exakte änderung oberste ']\n",
      "['algaddafi weltfriedens nachholen mörder“ sonderbehandlung windhose windhose windhose braucht hinterhalt ', 'lastwagenfahrer blöd zeigten lastwagenfahrer blöd zeigten janeiro exakte änderung oberste ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"anuj\",\"how are you?\"],inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('X_tokenizer.pickle', 'wb') as f:\n",
    "#     pickle.dump(inp_tokenizer, f)\n",
    "\n",
    "# with open('Y_tokenizer.pickle', 'wb') as f:\n",
    "#     pickle.dump(tar_tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "encoder_loaded = pickle.load(open('encoder_attention_v1.pickle', 'rb'))\n",
    "decoder_loaded = pickle.load(open('decoder_attention_v1.pickle', 'rb'))\n",
    "\n",
    "X_tokenizer_loaded = pickle.load(open('X_tokenizer.pickle', 'rb'))\n",
    "Y_tokenizer_loaded = pickle.load(open('Y_tokenizer.pickle', 'rb'))\n",
    "\n",
    "# print(translate([\"anuj\",\"how are you?\"],X_tokenizer_loaded,Y_tokenizer_loaded,encoder=encoder_loaded,decoder=decoder_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ignoriere roosevelt ', 'wie bist du ']\n",
      "['ignoriere roosevelt ', 'wie bist du ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"anuj\",\"how are you?\"],X_tokenizer_loaded,Y_tokenizer_loaded,encoder=encoder_loaded,decoder=decoder_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallo ', 'hallo ', 'renn ', 'potzdonner ', 'potzdonner ', 'feuer feuer ', 'unterstützt hilfe ', 'unterstützt hilfe ', 'hör auf ', 'warte ', 'geh rein ', 'halli hallo hallo hallo hallo hallo hallo hallo hallo hallo ', 'ich rannte gerannt ', 'aha ', 'aha ', 'ich probiere es an ', 'ich habe gewonnen ', 'ich habe gewonnen ', 'lächeln schwingt zu lächeln ', 'an der armbanduhr ', 'knie einfach ', 'knie einfach ', 'schalte es ', 'schalte es ', 'schalte es ', 'er rannte ', 'er rannte ', 'mach mach zu ', 'umarme mich ', 'umarme mich ', 'umarme mich ', 'ich bin hingefallen ', 'ich bin hingefallen ', 'ich bin hingefallen ', 'ich bin hingefallen ', 'ich bin hingefallen ', 'ich weiß ', 'ich habe gelogen ', 'ich habe verloren ', 'ich bezahlte ', 'ich bezahlte ', 'ich habe gesungen ', 'ich schwimme zurück ', 'ich bin 19 jahre alt ', 'ich bin 19 jahre alt ', 'ich bin ok ', 'ich bin ok ', 'ich bin begeistert ', 'ich bin begeistert ', 'ausgeschlossen ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenised Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hallo!</td>\n",
       "      <td>hallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Grüß Gott!</td>\n",
       "      <td>hallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lauf!</td>\n",
       "      <td>renn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Potzdonner!</td>\n",
       "      <td>potzdonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Donnerwetter!</td>\n",
       "      <td>potzdonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Feuer!</td>\n",
       "      <td>feuer feuer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Hilfe!</td>\n",
       "      <td>unterstützt hilfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Zu Hülf!</td>\n",
       "      <td>unterstützt hilfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>Stopp!</td>\n",
       "      <td>hör auf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>Warte!</td>\n",
       "      <td>warte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Go on.</td>\n",
       "      <td>Mach weiter.</td>\n",
       "      <td>geh rein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>Hallo!</td>\n",
       "      <td>halli hallo hallo hallo hallo hallo hallo hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I ran.</td>\n",
       "      <td>Ich rannte.</td>\n",
       "      <td>ich rannte gerannt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Ich verstehe.</td>\n",
       "      <td>aha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Aha.</td>\n",
       "      <td>aha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I try.</td>\n",
       "      <td>Ich probiere es.</td>\n",
       "      <td>ich probiere es an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I won!</td>\n",
       "      <td>Ich hab gewonnen!</td>\n",
       "      <td>ich habe gewonnen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I won!</td>\n",
       "      <td>Ich habe gewonnen!</td>\n",
       "      <td>ich habe gewonnen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Smile.</td>\n",
       "      <td>Lächeln!</td>\n",
       "      <td>lächeln schwingt zu lächeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cheers!</td>\n",
       "      <td>Zum Wohl!</td>\n",
       "      <td>an der armbanduhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Freeze!</td>\n",
       "      <td>Keine Bewegung!</td>\n",
       "      <td>knie einfach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Freeze!</td>\n",
       "      <td>Stehenbleiben!</td>\n",
       "      <td>knie einfach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Kapiert?</td>\n",
       "      <td>schalte es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Verstanden?</td>\n",
       "      <td>schalte es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Got it?</td>\n",
       "      <td>Einverstanden?</td>\n",
       "      <td>schalte es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>He ran.</td>\n",
       "      <td>Er rannte.</td>\n",
       "      <td>er rannte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>He ran.</td>\n",
       "      <td>Er lief.</td>\n",
       "      <td>er rannte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hop in.</td>\n",
       "      <td>Mach mit!</td>\n",
       "      <td>mach mach zu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Drück mich!</td>\n",
       "      <td>umarme mich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Nimm mich in den Arm!</td>\n",
       "      <td>umarme mich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hug me.</td>\n",
       "      <td>Umarme mich!</td>\n",
       "      <td>umarme mich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich fiel.</td>\n",
       "      <td>ich bin hingefallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich fiel hin.</td>\n",
       "      <td>ich bin hingefallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich stürzte.</td>\n",
       "      <td>ich bin hingefallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich bin hingefallen.</td>\n",
       "      <td>ich bin hingefallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I fell.</td>\n",
       "      <td>Ich bin gestürzt.</td>\n",
       "      <td>ich bin hingefallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I know.</td>\n",
       "      <td>Ich weiß.</td>\n",
       "      <td>ich weiß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I lied.</td>\n",
       "      <td>Ich habe gelogen.</td>\n",
       "      <td>ich habe gelogen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I lost.</td>\n",
       "      <td>Ich habe verloren.</td>\n",
       "      <td>ich habe verloren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I paid.</td>\n",
       "      <td>Ich habe bezahlt.</td>\n",
       "      <td>ich bezahlte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I paid.</td>\n",
       "      <td>Ich zahlte.</td>\n",
       "      <td>ich bezahlte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I sang.</td>\n",
       "      <td>Ich sang.</td>\n",
       "      <td>ich habe gesungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I swim.</td>\n",
       "      <td>Ich schwimme.</td>\n",
       "      <td>ich schwimme zurück</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>Ich bin 19 Jahre alt.</td>\n",
       "      <td>ich bin 19 jahre alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>Ich bin 19.</td>\n",
       "      <td>ich bin 19 jahre alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>Mir geht's gut.</td>\n",
       "      <td>ich bin ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>Es geht mir gut.</td>\n",
       "      <td>ich bin ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I'm up.</td>\n",
       "      <td>Ich bin wach.</td>\n",
       "      <td>ich bin begeistert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I'm up.</td>\n",
       "      <td>Ich bin auf.</td>\n",
       "      <td>ich bin begeistert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>No way!</td>\n",
       "      <td>Unmöglich!</td>\n",
       "      <td>ausgeschlossen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tokenised Original              Reference  \\\n",
       "0                 Hi.                 Hallo!   \n",
       "1                 Hi.             Grüß Gott!   \n",
       "2                Run!                  Lauf!   \n",
       "3                Wow!            Potzdonner!   \n",
       "4                Wow!          Donnerwetter!   \n",
       "5               Fire!                 Feuer!   \n",
       "6               Help!                 Hilfe!   \n",
       "7               Help!               Zu Hülf!   \n",
       "8               Stop!                 Stopp!   \n",
       "9               Wait!                 Warte!   \n",
       "10             Go on.           Mach weiter.   \n",
       "11             Hello!                 Hallo!   \n",
       "12             I ran.            Ich rannte.   \n",
       "13             I see.          Ich verstehe.   \n",
       "14             I see.                   Aha.   \n",
       "15             I try.       Ich probiere es.   \n",
       "16             I won!      Ich hab gewonnen!   \n",
       "17             I won!     Ich habe gewonnen!   \n",
       "18             Smile.               Lächeln!   \n",
       "19            Cheers!              Zum Wohl!   \n",
       "20            Freeze!        Keine Bewegung!   \n",
       "21            Freeze!         Stehenbleiben!   \n",
       "22            Got it?               Kapiert?   \n",
       "23            Got it?            Verstanden?   \n",
       "24            Got it?         Einverstanden?   \n",
       "25            He ran.             Er rannte.   \n",
       "26            He ran.               Er lief.   \n",
       "27            Hop in.              Mach mit!   \n",
       "28            Hug me.            Drück mich!   \n",
       "29            Hug me.  Nimm mich in den Arm!   \n",
       "30            Hug me.           Umarme mich!   \n",
       "31            I fell.              Ich fiel.   \n",
       "32            I fell.          Ich fiel hin.   \n",
       "33            I fell.           Ich stürzte.   \n",
       "34            I fell.   Ich bin hingefallen.   \n",
       "35            I fell.      Ich bin gestürzt.   \n",
       "36            I know.              Ich weiß.   \n",
       "37            I lied.      Ich habe gelogen.   \n",
       "38            I lost.     Ich habe verloren.   \n",
       "39            I paid.      Ich habe bezahlt.   \n",
       "40            I paid.            Ich zahlte.   \n",
       "41            I sang.              Ich sang.   \n",
       "42            I swim.          Ich schwimme.   \n",
       "43            I'm 19.  Ich bin 19 Jahre alt.   \n",
       "44            I'm 19.            Ich bin 19.   \n",
       "45            I'm OK.        Mir geht's gut.   \n",
       "46            I'm OK.       Es geht mir gut.   \n",
       "47            I'm up.          Ich bin wach.   \n",
       "48            I'm up.           Ich bin auf.   \n",
       "49            No way!             Unmöglich!   \n",
       "\n",
       "                                          Translation  \n",
       "0                                              hallo   \n",
       "1                                              hallo   \n",
       "2                                               renn   \n",
       "3                                         potzdonner   \n",
       "4                                         potzdonner   \n",
       "5                                        feuer feuer   \n",
       "6                                  unterstützt hilfe   \n",
       "7                                  unterstützt hilfe   \n",
       "8                                            hör auf   \n",
       "9                                              warte   \n",
       "10                                          geh rein   \n",
       "11  halli hallo hallo hallo hallo hallo hallo hall...  \n",
       "12                                ich rannte gerannt   \n",
       "13                                               aha   \n",
       "14                                               aha   \n",
       "15                                ich probiere es an   \n",
       "16                                 ich habe gewonnen   \n",
       "17                                 ich habe gewonnen   \n",
       "18                       lächeln schwingt zu lächeln   \n",
       "19                                 an der armbanduhr   \n",
       "20                                      knie einfach   \n",
       "21                                      knie einfach   \n",
       "22                                        schalte es   \n",
       "23                                        schalte es   \n",
       "24                                        schalte es   \n",
       "25                                         er rannte   \n",
       "26                                         er rannte   \n",
       "27                                      mach mach zu   \n",
       "28                                       umarme mich   \n",
       "29                                       umarme mich   \n",
       "30                                       umarme mich   \n",
       "31                               ich bin hingefallen   \n",
       "32                               ich bin hingefallen   \n",
       "33                               ich bin hingefallen   \n",
       "34                               ich bin hingefallen   \n",
       "35                               ich bin hingefallen   \n",
       "36                                          ich weiß   \n",
       "37                                  ich habe gelogen   \n",
       "38                                 ich habe verloren   \n",
       "39                                      ich bezahlte   \n",
       "40                                      ich bezahlte   \n",
       "41                                 ich habe gesungen   \n",
       "42                               ich schwimme zurück   \n",
       "43                              ich bin 19 jahre alt   \n",
       "44                              ich bin 19 jahre alt   \n",
       "45                                        ich bin ok   \n",
       "46                                        ich bin ok   \n",
       "47                                ich bin begeistert   \n",
       "48                                ich bin begeistert   \n",
       "49                                    ausgeschlossen   "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df(lines,encoder_loaded,decoder_loaded,X_tokenizer_loaded,Y_tokenizer_loaded)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
