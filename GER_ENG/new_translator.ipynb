{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 50\n",
    "UNITS = 50\n",
    "NUM_EPOCHS = 20\n",
    "max_lines = 180000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent, exclude, sp_tokens=False):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(\"'\", '', sent)\n",
    "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(\" +\", \" \", sent)\n",
    "    if sp_tokens:\n",
    "        sent = '<start> ' + sent + ' <end>'\n",
    "    \n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def Tokenize(text):\n",
    "    tokenizer = Tokenizer(oov_token=\"<unk>\",filters='!\"#$%&()*+,-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def pad_sequences(x, max_len):\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=max_len, padding='post', truncating='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!', 'Run!\\tLauf!', 'Wow!\\tPotzdonner!', 'Wow!\\tDonnerwetter!']\n"
     ]
    }
   ],
   "source": [
    "lines = load_data(\"eng_ger.txt\")\n",
    "lines = lines[:max_lines]\n",
    "\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi.\\tHallo!', 'Hi.\\tGrüß Gott!', 'Run!\\tLauf!', 'Wow!\\tPotzdonner!', 'Wow!\\tDonnerwetter!']\n",
      "['Hallo!\\tHi.', 'Grüß Gott!\\tHi.', 'Lauf!\\tRun!', 'Potzdonner!\\tWow!', 'Donnerwetter!\\tWow!']\n"
     ]
    }
   ],
   "source": [
    "def swap_lines(lines):\n",
    "    print(lines[:5])\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        text = line.split(\"\\t\")\n",
    "        str = text[1] + \"\\t\" + text[0]\n",
    "        data.append(str)\n",
    "    return data\n",
    "\n",
    "lines = swap_lines(lines)\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(lines):\n",
    "    data = []\n",
    "    exclude = string.punctuation\n",
    "    for line in lines:\n",
    "        text = line.split(\"\\t\")\n",
    "        prep_inp = preprocess(text[0], exclude=exclude, sp_tokens=False)\n",
    "        prep_tar = preprocess(text[1], exclude=exclude, sp_tokens=True)\n",
    "        data.append([prep_inp, prep_tar])\n",
    "    \n",
    "    print(data[:5])\n",
    "    \n",
    "    # tokenize\n",
    "    inp_tokenizer = Tokenize([i[0] for i in data])\n",
    "    tar_tokenizer = Tokenize([i[1] for i in data])\n",
    "\n",
    "    # convert text to sequences\n",
    "    inp_seq = inp_tokenizer.texts_to_sequences([i[0] for i in data])\n",
    "    tar_seq = tar_tokenizer.texts_to_sequences([i[1] for i in data])\n",
    "\n",
    "    print(inp_seq[:5])\n",
    "    print(tar_seq[:5])\n",
    "\n",
    "    # padding\n",
    "    inp_seq = pad_sequences(inp_seq, max_len=10)\n",
    "    tar_seq = pad_sequences(tar_seq, max_len=10)\n",
    "\n",
    "    print(inp_seq[:5])\n",
    "    print(tar_seq[:5])\n",
    "\n",
    "    input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(inp_seq, tar_seq, test_size=0.2)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(len(input_tensor_val))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "    return train_dataset, test_dataset, inp_tokenizer, tar_tokenizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hallo', '<start> hi <end>'], ['grüß gott', '<start> hi <end>'], ['lauf', '<start> run <end>'], ['potzdonner', '<start> wow <end>'], ['donnerwetter', '<start> wow <end>']]\n",
      "[[1596], [4077, 1513], [4508], [10094], [12452]]\n",
      "[[2, 2059, 3], [2, 2059, 3], [2, 461, 3], [2, 3726, 3], [2, 3726, 3]]\n",
      "[[ 1596     0     0     0     0     0     0     0     0     0]\n",
      " [ 4077  1513     0     0     0     0     0     0     0     0]\n",
      " [ 4508     0     0     0     0     0     0     0     0     0]\n",
      " [10094     0     0     0     0     0     0     0     0     0]\n",
      " [12452     0     0     0     0     0     0     0     0     0]]\n",
      "[[   2 2059    3    0    0    0    0    0    0    0]\n",
      " [   2 2059    3    0    0    0    0    0    0    0]\n",
      " [   2  461    3    0    0    0    0    0    0    0]\n",
      " [   2 3726    3    0    0    0    0    0    0    0]\n",
      " [   2 3726    3    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, inp_tokenizer, tar_tokenizer = combine(lines)\n",
    "input_vocab_size = len(inp_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(tar_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 10), dtype=tf.int32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(token,tokenizer):\n",
    "    # token = token.numpy()\n",
    "    res = \"\"\n",
    "    for i in token:\n",
    "        if i!=0:\n",
    "            if(tokenizer.index_word[i]==\"<end>\"):\n",
    "                break\n",
    "            if(tokenizer.index_word[i]==\"<start>\"):\n",
    "                continue\n",
    "            res += tokenizer.index_word[i] + \" \"\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layers => 1 embedding layer and 1 LSTM layer\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, units, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim, mask_zero=True)\n",
    "        self.rnn = tf.keras.layers.LSTM(\n",
    "            units, return_sequences=True, return_state=True)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # x => (batch_size, max_len)\n",
    "        x = self.embedding(x) # => (batch_size, s, embed_dim)\n",
    "        enc_outputs = self.rnn(x)\n",
    "        return enc_outputs[0], enc_outputs[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W_q = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W_k = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W_v = tf.keras.layers.Dense(1, use_bias=False)\n",
    "    \n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        query, key = self.W_q(query), self.W_k(key)\n",
    "        # query => (batch_size, t, units)\n",
    "        # key => (batch_size, s, units)\n",
    "\n",
    "        score = self.W_v(\n",
    "            tf.math.tanh(\n",
    "                tf.expand_dims(query, 2) + tf.expand_dims(key, 1)\n",
    "            )\n",
    "        )\n",
    "        score = tf.squeeze(score, -1)\n",
    "        # score => (batch_size, t, s)\n",
    "        \n",
    "        if mask is not None:\n",
    "            score = tf.where(mask, score, -1e6)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        # attention_weights => (batch_size, t, s)\n",
    "\n",
    "        context = tf.matmul(attention_weights, value)\n",
    "        # context => (batch_size, t, units)\n",
    "\n",
    "        return context, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, units, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer to convert tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embed_dim, mask_zero=True)\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = tf.keras.layers.LSTM(\n",
    "            units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = AdditiveAttention(units)\n",
    "\n",
    "        # Final layer to output logits, we can use \n",
    "        # argmax to know which output token is predicted.\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "\n",
    "    def call(self, x, enc_outputs, state, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        # x => (batch_size, t, embed_dim)\n",
    "\n",
    "        dec_outputs = self.rnn(x, initial_state=state)\n",
    "        output = dec_outputs[0]\n",
    "        state = dec_outputs[1:]\n",
    "        # output   => (batch_size, t, units) \n",
    "        # state[i] => (batch_size, s, units)\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            query=output,\n",
    "            key=enc_outputs,\n",
    "            value=enc_outputs,\n",
    "            mask=mask\n",
    "        )\n",
    "        # context_vector => (batch_size, t, units)\n",
    "        # attention_weights => (batch_size, t, s)\n",
    "\n",
    "        context_rnn_output = tf.concat(\n",
    "            [context_vector, output], axis=-1)\n",
    "        # context_rnn_output => (batch_size, t, 2*units)\n",
    "\n",
    "        pred = self.fc(context_rnn_output)\n",
    "        # pred => (batch_size, t, vocab_size)\n",
    "        \n",
    "        return pred, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instances of encoder and decoder\n",
    "encoder = Encoder(EMBEDDING_DIM, UNITS, input_vocab_size)\n",
    "decoder = Decoder(EMBEDDING_DIM, UNITS, target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    # y_true => (batch_size, max_len)\n",
    "    # y_pred => (batch_size, max_len, vocab_size)\n",
    "\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # masking the padding tokens\n",
    "    loss = tf.reduce_sum(loss * mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "trainer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'loss': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:59<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 2.583944691869948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [08:08<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.465158718691932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:47<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 1.1782671457131704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:44<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 1.0367320578893027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:45<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 0.9540529803435007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:49<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 0.9036036790211995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:45<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 0.8690587290128072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:49<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 0.8433906269868215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:58<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 0.8253486248387231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:57<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 0.810462548467848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:57<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.7992745428085327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:56<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 0.7897324363655515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:57<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 0.7821619648668501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:58<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 0.7759963727659649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:57<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 0.7688419106933806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [08:17<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 0.7670986092090607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [08:22<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 0.7654236648347643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:58<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 0.7637739181783464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [07:54<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 0.7599073525799646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [08:02<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 0.7592152256303364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0.\n",
    "\n",
    "    with tqdm(total=len(train_dataset)) as pbar:\n",
    "        for batch, (x, y) in enumerate(train_dataset):\n",
    "            inp_mask = tf.expand_dims(x != 0, axis=1)\n",
    "            tgt_mask = tf.cast(y != 0, tf.float32)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = tf.constant(0.0)\n",
    "                enc_outputs, enc_states = encoder(x)\n",
    "                dec_states = enc_states\n",
    "\n",
    "                dec_input = tf.expand_dims(y[:, 0], axis=1)\n",
    "                for t in range(1, x.shape[1]):\n",
    "                    dec_outputs, dec_states, tmp_a = decoder(\n",
    "                        dec_input, enc_outputs, \n",
    "                        dec_states, inp_mask)\n",
    "\n",
    "                    loss += loss_fn(\n",
    "                        tf.expand_dims(y[:, t], axis=1), dec_outputs)\n",
    "                    dec_input = tf.expand_dims(y[:, t], axis=1)\n",
    "                    \n",
    "                loss = loss/tf.reduce_sum(tgt_mask)\n",
    "            \n",
    "            variables = (encoder.trainable_variables + \n",
    "            decoder.trainable_variables)\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            trainer.apply_gradients(zip(gradients, variables))\n",
    "            total_loss += loss.numpy()\n",
    "            pbar.update(1)\n",
    "        \n",
    "    epoch_loss = total_loss/len(train_dataset)\n",
    "    history['loss'].append(epoch_loss)\n",
    "    print(f'Epoch: {epoch} | Loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = list(range(len(history['loss'])))\n",
    "plt.plot(epochs, history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_tokenizer.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(encoder, decoder, src_tokens, tar_tokenizer, num_steps):\n",
    "    enc_X = tf.expand_dims(src_tokens, axis=0)\n",
    "    mask = tf.expand_dims(enc_X != 0, 1)\n",
    "\n",
    "    enc_outputs, enc_state = encoder(enc_X, training=False)\n",
    "    dec_state = enc_state\n",
    "    dec_X = tf.expand_dims(tf.constant([tar_tokenizer.word_index['<start>']]), axis=0)\n",
    "    output_seq = []\n",
    "    attention_weights = []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state, att_wgts = decoder(\n",
    "            dec_X, enc_outputs, dec_state, mask,training=False)\n",
    "        dec_X = tf.argmax(Y, axis=2)\n",
    "        pred = tf.squeeze(dec_X, axis=0)\n",
    "        if pred[0].numpy() == tar_tokenizer.word_index['<end>']:\n",
    "            break\n",
    "        output_seq.append(pred[0].numpy())\n",
    "        attention_weights.append(tf.squeeze(att_wgts, 0))\n",
    "    attention_weights = tf.squeeze(tf.stack(attention_weights, axis=0), 1)\n",
    "    return detokenize(output_seq, tar_tokenizer), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng, hin = next(iter(train_dataset))\n",
    "# print(train_dataset)\n",
    "# print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mag solche dinge \n",
      "Input Sentence:      ich mag solche dinge \n",
      "Predicted Translation: uniforms questioning gymnasium untidy contemptuously age ends measurement outlaw bomb \n",
      "Actual Translation:    i like to do things like that \n"
     ]
    }
   ],
   "source": [
    "idx = -5\n",
    "actual_seq = detokenize(hin[idx].numpy(),tar_tokenizer)\n",
    "translation, att_wgts = predict_seq2seq(encoder, decoder, eng[idx], tar_tokenizer, 10)\n",
    "eng_sent = detokenize(eng[idx].numpy(), inp_tokenizer)\n",
    "print(eng_sent)\n",
    "print(f'Input Sentence:      {eng_sent}')\n",
    "print(f'Predicted Translation: {translation}')\n",
    "print(f'Actual Translation:    {actual_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(lines,inp_tokenizer,tar_tokenizer,encoder,decoder,max_len=10):\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    prep_lines = []\n",
    "\n",
    "    for i in lines:\n",
    "        prep_lines.append([preprocess(i, exclude, sp_tokens=False)])\n",
    "    \n",
    "    input_tensors = []\n",
    "\n",
    "    for i in prep_lines:\n",
    "        inp = i[0].split(' ')\n",
    "        tensor = []\n",
    "        for j in inp:\n",
    "            # check for oov\n",
    "            if j not in inp_tokenizer.word_index.keys():\n",
    "                tensor.append(inp_tokenizer.word_index['<unk>'])\n",
    "            else:\n",
    "                tensor.append(inp_tokenizer.word_index[j])\n",
    "        input_tensors.append(tensor)\n",
    "            \n",
    "    for input_tensor in input_tensors:\n",
    "        temp_max_len = max(max_len,len(input_tensor))\n",
    "        for i in range(temp_max_len-len(input_tensor)):\n",
    "            input_tensor.append(0)\n",
    "\n",
    "    for input_tensor in input_tensors:\n",
    "        input_tensor = tf.convert_to_tensor(input_tensor)\n",
    "\n",
    "    translations = []\n",
    "\n",
    "    for input_tensor in input_tensors:\n",
    "        translation, _ = predict_seq2seq(encoder, decoder, input_tensor, tar_tokenizer,10)\n",
    "        translations.append(translation)\n",
    "    \n",
    "    print(translations) \n",
    "    \n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accepted skunk connected fantastic signs blame download download bewildered bewildered ', 'accepted accepted skunk inhibitions signs download download bewildered signs blame ']\n",
      "['accepted skunk connected fantastic signs blame download download bewildered bewildered ', 'accepted accepted skunk inhibitions signs download download bewildered signs blame ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"anuj\",\"how are you?\"],inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(lines):\n",
    "    translation = {'Tokenised Original':[],'Reference':[],'Translation':[]}\n",
    "    lines = lines[:50]\n",
    "    text = []\n",
    "    ref = []\n",
    "    trans = []\n",
    "    for i in lines:\n",
    "        t = i.split('\\t')\n",
    "        text.append(t[0])\n",
    "        ref.append(t[1])   \n",
    "    trans = translate(text,inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder)\n",
    "    for i in range(len(trans)):\n",
    "        translation['Tokenised Original'].append(text[i])\n",
    "        translation['Reference'].append(ref[i])\n",
    "        translation['Translation'].append(trans[i])\n",
    "    df = pd.DataFrame(translation)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['farther unintelligent ah swelling liquid locating bookkeeping climb foots wellbeing ', 'digital gucci soldiers gain soldiers secondrate mother microscope crouched digital ', 'lavender fortunately index loud loud loud approximately loud loud sprouted ', 'decorating talk faded lifeordeath granted granted student squatting chalk gi ', 'liquor blackie deal boards cooler crafty crafty skateboard york york ', '1941 updated horn 89 undefeated 89 mock alice alice beasts ', 'squeaked solomon brushed diagonally precious diagonally precious solomon brushed brushed ', 'spotlight lent reply snoozed snoozed simplest delete fog simplest fog ', 'astonishment dwell eats advantage embarrassing juice slam opposing around bullet ', 'worry diamonds orbits intellectual worry brighten fax robe most divorces ', 'sandwich sandwich ironic bare valentina maruzen mustaches unfolded maruzen unfolded ', 'farther unintelligent ah swelling liquid locating bookkeeping climb foots wellbeing ', 'jeep beards unfortunate environments thumb thumb thumb thumb ladybug thumb ', 'jeep pays eighty eighty lessened heir heir reincarnation corner masochist ', 'celsius rigid breeding solving thicker pile pile lowcost suspicion suspicion ', 'wash thunder simplest simplest stirring associated associated associated random random ', 'thered thered neurotic nextdoor nextdoor nextdoor nero delivers combine inevitable ', 'jeep astrology environments heirlooms unlike recession mums euro battleship pockets ', 'tenspeed potters bluffing stormed brides boxer rush rush rush financially ', 'needs needs bearded competence competence competence snowflakes turning martin dad ', 'radar less ends utterly anniversaries serpent spike sermon advantage embarrassing ', 'therapy therapy skin green wrap brunettes ukrainian suspenders locals hear ', 'forming reconcile rational illusion credit chases credit haley mornings watches ', 'yielded erased yielded gave gave shortterm shortterm reapply grind polka ', 'yielded yielded guide handtomouth high ashes napping kitten dizzy yielded ', 'chalk search fashioned suffering seattle discrimination discrimination accepting far respected ', '27th 27th shower troublemaker troublemaker snowfall neat slippers historical yes ', 'cheese dispute bay lumber that\\xa0as seat empties 120 segment regret ', 'reign legendary legendary exact odd boat housewife oceans reputable marlowe ', 'weed costume ours tormented corners pregnant history senselessness sweeping sweeping ', 'sneeze intense neurotic neurotic thousands laughing nearer nearer nearer departs ', 'baseball consist plants plants plants immigrated history butterflys heroic unfaithful ', 'catalogue backpack manner unopened unopened nigger collected asking unfaithful absorbed ', 'jeep ammonia bachelor pansies bachelor bean doctors doctors thigh niece ', 'wash assassin suppressed backwards ascended unfaithful human parents autistic tennessee ', 'ascended placebo ladybug cricket blackberries forged blackberries billions retired retired ', 'stupidity an 24100 daydreaming popularize an grain truth ship placebo ', 'jeep physically ammonia ladybug corner bracelet quincy likeable creationist extravagant ', 'creeps squeaked lodging contemptuously h₂o ladybug interrupted spicy sealed poorer ', 'baseball airraid gangster pansies poster footprint martial sunday assuming positive ', 'jeep pays elizabeth artillery catalogue relax doctors doctors doctors thigh ', 'jeep astrology proposed astrology material colonies stone bomb measurement outlaw ', 'never ends consist acute restaurant libraries men cocacola incapable incapable ', 'creeps creeps spider eighty eighty tattooed possess possess empties grizzly ', 'wash altar magellan chemical exaggerate exaggerate exaggerate exaggerate assisted portions ', '89 nun nun nun nun nun nun nun nun nun ', 'squirrel jeep jeep physically developments over over lion lion prescribed ', 'uphill spends lunar blackie dwell throwing meat disgrace actor meat ', 'down down down mugs seldom russian summarily horn empties reincarnation ', 'boarded bank canned racist busier humid clouds snowflakes snowflakes immortality ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenised Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hallo!</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>farther unintelligent ah swelling liquid locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grüß Gott!</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>digital gucci soldiers gain soldiers secondrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lauf!</td>\n",
       "      <td>Run!</td>\n",
       "      <td>lavender fortunately index loud loud loud appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Potzdonner!</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>decorating talk faded lifeordeath granted gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donnerwetter!</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>liquor blackie deal boards cooler crafty craft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feuer!</td>\n",
       "      <td>Fire!</td>\n",
       "      <td>1941 updated horn 89 undefeated 89 mock alice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hilfe!</td>\n",
       "      <td>Help!</td>\n",
       "      <td>squeaked solomon brushed diagonally precious d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zu Hülf!</td>\n",
       "      <td>Help!</td>\n",
       "      <td>spotlight lent reply snoozed snoozed simplest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stopp!</td>\n",
       "      <td>Stop!</td>\n",
       "      <td>astonishment dwell eats advantage embarrassing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warte!</td>\n",
       "      <td>Wait!</td>\n",
       "      <td>worry diamonds orbits intellectual worry brigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mach weiter.</td>\n",
       "      <td>Go on.</td>\n",
       "      <td>sandwich sandwich ironic bare valentina maruze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hallo!</td>\n",
       "      <td>Hello!</td>\n",
       "      <td>farther unintelligent ah swelling liquid locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ich rannte.</td>\n",
       "      <td>I ran.</td>\n",
       "      <td>jeep beards unfortunate environments thumb thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ich verstehe.</td>\n",
       "      <td>I see.</td>\n",
       "      <td>jeep pays eighty eighty lessened heir heir rei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aha.</td>\n",
       "      <td>I see.</td>\n",
       "      <td>celsius rigid breeding solving thicker pile pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ich probiere es.</td>\n",
       "      <td>I try.</td>\n",
       "      <td>wash thunder simplest simplest stirring associ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ich hab gewonnen!</td>\n",
       "      <td>I won!</td>\n",
       "      <td>thered thered neurotic nextdoor nextdoor nextd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ich habe gewonnen!</td>\n",
       "      <td>I won!</td>\n",
       "      <td>jeep astrology environments heirlooms unlike r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lächeln!</td>\n",
       "      <td>Smile.</td>\n",
       "      <td>tenspeed potters bluffing stormed brides boxer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Zum Wohl!</td>\n",
       "      <td>Cheers!</td>\n",
       "      <td>needs needs bearded competence competence comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Keine Bewegung!</td>\n",
       "      <td>Freeze!</td>\n",
       "      <td>radar less ends utterly anniversaries serpent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Stehenbleiben!</td>\n",
       "      <td>Freeze!</td>\n",
       "      <td>therapy therapy skin green wrap brunettes ukra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kapiert?</td>\n",
       "      <td>Got it?</td>\n",
       "      <td>forming reconcile rational illusion credit cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Verstanden?</td>\n",
       "      <td>Got it?</td>\n",
       "      <td>yielded erased yielded gave gave shortterm sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Einverstanden?</td>\n",
       "      <td>Got it?</td>\n",
       "      <td>yielded yielded guide handtomouth high ashes n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Er rannte.</td>\n",
       "      <td>He ran.</td>\n",
       "      <td>chalk search fashioned suffering seattle discr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Er lief.</td>\n",
       "      <td>He ran.</td>\n",
       "      <td>27th 27th shower troublemaker troublemaker sno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mach mit!</td>\n",
       "      <td>Hop in.</td>\n",
       "      <td>cheese dispute bay lumber that as seat empties...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Drück mich!</td>\n",
       "      <td>Hug me.</td>\n",
       "      <td>reign legendary legendary exact odd boat house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nimm mich in den Arm!</td>\n",
       "      <td>Hug me.</td>\n",
       "      <td>weed costume ours tormented corners pregnant h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Umarme mich!</td>\n",
       "      <td>Hug me.</td>\n",
       "      <td>sneeze intense neurotic neurotic thousands lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ich fiel.</td>\n",
       "      <td>I fell.</td>\n",
       "      <td>baseball consist plants plants plants immigrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ich fiel hin.</td>\n",
       "      <td>I fell.</td>\n",
       "      <td>catalogue backpack manner unopened unopened ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ich stürzte.</td>\n",
       "      <td>I fell.</td>\n",
       "      <td>jeep ammonia bachelor pansies bachelor bean do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ich bin hingefallen.</td>\n",
       "      <td>I fell.</td>\n",
       "      <td>wash assassin suppressed backwards ascended un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ich bin gestürzt.</td>\n",
       "      <td>I fell.</td>\n",
       "      <td>ascended placebo ladybug cricket blackberries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ich weiß.</td>\n",
       "      <td>I know.</td>\n",
       "      <td>stupidity an 24100 daydreaming popularize an g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ich habe gelogen.</td>\n",
       "      <td>I lied.</td>\n",
       "      <td>jeep physically ammonia ladybug corner bracele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ich habe verloren.</td>\n",
       "      <td>I lost.</td>\n",
       "      <td>creeps squeaked lodging contemptuously h₂o lad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ich habe bezahlt.</td>\n",
       "      <td>I paid.</td>\n",
       "      <td>baseball airraid gangster pansies poster footp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ich zahlte.</td>\n",
       "      <td>I paid.</td>\n",
       "      <td>jeep pays elizabeth artillery catalogue relax ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ich sang.</td>\n",
       "      <td>I sang.</td>\n",
       "      <td>jeep astrology proposed astrology material col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ich schwimme.</td>\n",
       "      <td>I swim.</td>\n",
       "      <td>never ends consist acute restaurant libraries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ich bin 19 Jahre alt.</td>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>creeps creeps spider eighty eighty tattooed po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ich bin 19.</td>\n",
       "      <td>I'm 19.</td>\n",
       "      <td>wash altar magellan chemical exaggerate exagge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mir geht's gut.</td>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>89 nun nun nun nun nun nun nun nun nun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Es geht mir gut.</td>\n",
       "      <td>I'm OK.</td>\n",
       "      <td>squirrel jeep jeep physically developments ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ich bin wach.</td>\n",
       "      <td>I'm up.</td>\n",
       "      <td>uphill spends lunar blackie dwell throwing mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ich bin auf.</td>\n",
       "      <td>I'm up.</td>\n",
       "      <td>down down down mugs seldom russian summarily h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Unmöglich!</td>\n",
       "      <td>No way!</td>\n",
       "      <td>boarded bank canned racist busier humid clouds...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokenised Original Reference  \\\n",
       "0                  Hallo!       Hi.   \n",
       "1              Grüß Gott!       Hi.   \n",
       "2                   Lauf!      Run!   \n",
       "3             Potzdonner!      Wow!   \n",
       "4           Donnerwetter!      Wow!   \n",
       "5                  Feuer!     Fire!   \n",
       "6                  Hilfe!     Help!   \n",
       "7                Zu Hülf!     Help!   \n",
       "8                  Stopp!     Stop!   \n",
       "9                  Warte!     Wait!   \n",
       "10           Mach weiter.    Go on.   \n",
       "11                 Hallo!    Hello!   \n",
       "12            Ich rannte.    I ran.   \n",
       "13          Ich verstehe.    I see.   \n",
       "14                   Aha.    I see.   \n",
       "15       Ich probiere es.    I try.   \n",
       "16      Ich hab gewonnen!    I won!   \n",
       "17     Ich habe gewonnen!    I won!   \n",
       "18               Lächeln!    Smile.   \n",
       "19              Zum Wohl!   Cheers!   \n",
       "20        Keine Bewegung!   Freeze!   \n",
       "21         Stehenbleiben!   Freeze!   \n",
       "22               Kapiert?   Got it?   \n",
       "23            Verstanden?   Got it?   \n",
       "24         Einverstanden?   Got it?   \n",
       "25             Er rannte.   He ran.   \n",
       "26               Er lief.   He ran.   \n",
       "27              Mach mit!   Hop in.   \n",
       "28            Drück mich!   Hug me.   \n",
       "29  Nimm mich in den Arm!   Hug me.   \n",
       "30           Umarme mich!   Hug me.   \n",
       "31              Ich fiel.   I fell.   \n",
       "32          Ich fiel hin.   I fell.   \n",
       "33           Ich stürzte.   I fell.   \n",
       "34   Ich bin hingefallen.   I fell.   \n",
       "35      Ich bin gestürzt.   I fell.   \n",
       "36              Ich weiß.   I know.   \n",
       "37      Ich habe gelogen.   I lied.   \n",
       "38     Ich habe verloren.   I lost.   \n",
       "39      Ich habe bezahlt.   I paid.   \n",
       "40            Ich zahlte.   I paid.   \n",
       "41              Ich sang.   I sang.   \n",
       "42          Ich schwimme.   I swim.   \n",
       "43  Ich bin 19 Jahre alt.   I'm 19.   \n",
       "44            Ich bin 19.   I'm 19.   \n",
       "45        Mir geht's gut.   I'm OK.   \n",
       "46       Es geht mir gut.   I'm OK.   \n",
       "47          Ich bin wach.   I'm up.   \n",
       "48           Ich bin auf.   I'm up.   \n",
       "49             Unmöglich!   No way!   \n",
       "\n",
       "                                          Translation  \n",
       "0   farther unintelligent ah swelling liquid locat...  \n",
       "1   digital gucci soldiers gain soldiers secondrat...  \n",
       "2   lavender fortunately index loud loud loud appr...  \n",
       "3   decorating talk faded lifeordeath granted gran...  \n",
       "4   liquor blackie deal boards cooler crafty craft...  \n",
       "5   1941 updated horn 89 undefeated 89 mock alice ...  \n",
       "6   squeaked solomon brushed diagonally precious d...  \n",
       "7   spotlight lent reply snoozed snoozed simplest ...  \n",
       "8   astonishment dwell eats advantage embarrassing...  \n",
       "9   worry diamonds orbits intellectual worry brigh...  \n",
       "10  sandwich sandwich ironic bare valentina maruze...  \n",
       "11  farther unintelligent ah swelling liquid locat...  \n",
       "12  jeep beards unfortunate environments thumb thu...  \n",
       "13  jeep pays eighty eighty lessened heir heir rei...  \n",
       "14  celsius rigid breeding solving thicker pile pi...  \n",
       "15  wash thunder simplest simplest stirring associ...  \n",
       "16  thered thered neurotic nextdoor nextdoor nextd...  \n",
       "17  jeep astrology environments heirlooms unlike r...  \n",
       "18  tenspeed potters bluffing stormed brides boxer...  \n",
       "19  needs needs bearded competence competence comp...  \n",
       "20  radar less ends utterly anniversaries serpent ...  \n",
       "21  therapy therapy skin green wrap brunettes ukra...  \n",
       "22  forming reconcile rational illusion credit cha...  \n",
       "23  yielded erased yielded gave gave shortterm sho...  \n",
       "24  yielded yielded guide handtomouth high ashes n...  \n",
       "25  chalk search fashioned suffering seattle discr...  \n",
       "26  27th 27th shower troublemaker troublemaker sno...  \n",
       "27  cheese dispute bay lumber that as seat empties...  \n",
       "28  reign legendary legendary exact odd boat house...  \n",
       "29  weed costume ours tormented corners pregnant h...  \n",
       "30  sneeze intense neurotic neurotic thousands lau...  \n",
       "31  baseball consist plants plants plants immigrat...  \n",
       "32  catalogue backpack manner unopened unopened ni...  \n",
       "33  jeep ammonia bachelor pansies bachelor bean do...  \n",
       "34  wash assassin suppressed backwards ascended un...  \n",
       "35  ascended placebo ladybug cricket blackberries ...  \n",
       "36  stupidity an 24100 daydreaming popularize an g...  \n",
       "37  jeep physically ammonia ladybug corner bracele...  \n",
       "38  creeps squeaked lodging contemptuously h₂o lad...  \n",
       "39  baseball airraid gangster pansies poster footp...  \n",
       "40  jeep pays elizabeth artillery catalogue relax ...  \n",
       "41  jeep astrology proposed astrology material col...  \n",
       "42  never ends consist acute restaurant libraries ...  \n",
       "43  creeps creeps spider eighty eighty tattooed po...  \n",
       "44  wash altar magellan chemical exaggerate exagge...  \n",
       "45            89 nun nun nun nun nun nun nun nun nun   \n",
       "46  squirrel jeep jeep physically developments ove...  \n",
       "47  uphill spends lunar blackie dwell throwing mea...  \n",
       "48  down down down mugs seldom russian summarily h...  \n",
       "49  boarded bank canned racist busier humid clouds...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df(lines)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('encoder_attention_v1.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "with open('decoder_attention_v1.pickle', 'wb') as f:\n",
    "    pickle.dump(decoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answering mysteries crossbow inflatable llama filled grapevine aardvarks done must ']\n",
      "['answering mysteries crossbow inflatable llama filled grapevine aardvarks done must ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"wo ist er\"],inp_tokenizer,tar_tokenizer,encoder=encoder,decoder=decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(inp_tokenizer, f)\n",
    "\n",
    "with open('Y_tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tar_tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# encoder_loaded = pickle.load(open('encoder_attention_v1.pickle', 'rb'))\n",
    "# decoder_loaded = pickle.load(open('decoder_attention_v1.pickle', 'rb'))\n",
    "\n",
    "\n",
    "# print(encoder_loaded)\n",
    "# print(decoder_loaded)\n",
    "X_tokenizer_loaded = pickle.load(open('X_tokenizer.pickle', 'rb'))\n",
    "Y_tokenizer_loaded = pickle.load(open('Y_tokenizer.pickle', 'rb'))\n",
    "\n",
    "# print(translate([\"ich bin klug\"],X_tokenizer_loaded,Y_tokenizer_loaded,encoder=encoder_loaded,decoder=decoder_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoder_attention_v1.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder_loaded = pickle.load(open('encoder_attention_v1.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im easygoing ']\n",
      "['im easygoing ']\n"
     ]
    }
   ],
   "source": [
    "print(translate([\"ich bin\"],X_tokenizer_loaded,Y_tokenizer_loaded,encoder=encoder_loaded,decoder=decoder_loaded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
